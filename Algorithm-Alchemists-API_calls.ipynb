{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Calls and CSV Files Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies & setup\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygwalker as pyg\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fidel - City Coordinates CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config information.\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"metric\"\n",
    "\n",
    "# Build partial query URL\n",
    "base_url = f\"{url}appid={api_key}&units={units}&q=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of cities\n",
    "cities = [\"Paris\", \"London\", \"Barcelona\", \"Beijing\", \"Mumbai\", \"Tokyo\", \"New York\", \"Seattle\", \"Dallas\", \"Sydney\",\"Melbourne\", \"Cairo\",\"Johannesburg\", \"Lagos\" , \"Sao Paulo\", \"Buenos Aires\",\"Bogota\"]\n",
    "\n",
    "# set up lists to hold reponse info\n",
    "lat = []\n",
    "lon= []\n",
    "temp = []\n",
    "\n",
    "# Loop through the list of cities and perform a request for data on each\n",
    "for city in cities:\n",
    "    response = requests.get(base_url + city).json()\n",
    "    lat.append(response['coord']['lat'])\n",
    "    temp.append(response['main']['temp'])\n",
    "    lon.append(response['coord']['lon'])\n",
    "\n",
    "print(f\"The latitude information received is: {lat}\")\n",
    "print(f\"The temperature information received is: {lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame from cities, lat, and temp\n",
    "city_dict = {\n",
    "    \"city\": cities,\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon\n",
    "}\n",
    "city_data = pd.DataFrame(city_dict)\n",
    "city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame from cities, lat, and temp\n",
    "city_dict = {\n",
    "    \"city\": cities,\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon\n",
    "}\n",
    "city_data = pd.DataFrame(city_dict)\n",
    "city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'city_coordinates.csv'\n",
    "city_data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natalia - CO2 data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make API Call and Get JSON Data\n",
    "url = 'https://global-warming.org/api/co2-api'\n",
    "\n",
    "co2_response = requests.get(url)\n",
    "\n",
    "print(co2_response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if co2_response.status_code == 200:\n",
    "    data = co2_response.json()\n",
    "else:\n",
    "    print(\"Failed to fetch data from the API.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON to a File\n",
    "with open('data.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON Data\n",
    "with open('data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to CSV\n",
    "csv_data = []\n",
    "for item in data['co2']:\n",
    "    csv_data.append([item['year'], item['month'], item['day'], item['cycle'], item['trend']])\n",
    "    #print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV to \"resources\" Folder\n",
    "# Define the CSV file\n",
    "csv_file_path = os.path.join('../../Resources/co2_data.csv')\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['year', 'month', 'day', 'cycle', 'trend'])\n",
    "    csv_writer.writerows(csv_data)\n",
    "\n",
    "print(f'CSV file saved to: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natalia - Global Air Pollution CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct CSV download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mavin - Global Land Temp Anomalies CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct CSV download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mavin - Global Ocean Temp Anomalies CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct CSV download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mavin - Global Ocean Warming CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# New API URL\n",
    "url = \"https://global-warming.org/api/ocean-warming-api\"\n",
    "\n",
    "try:\n",
    "    # Make the API request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Parse the JSON response\n",
    "\n",
    "        # Extract the result dictionary from the data\n",
    "        result = data['result']\n",
    "\n",
    "        # Convert string values to floats\n",
    "        ocean_warming_data = {year: float(value) for year, value in result.items()}\n",
    "\n",
    "        # Save data to a CSV file\n",
    "        with open(\"ocean_warming_data.csv\", mode=\"w\", newline=\"\") as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([\"Year\", \"Ocean Warming (°C)\"])  # Write header\n",
    "            for year, value in ocean_warming_data.items():\n",
    "                csv_writer.writerow([year, value])\n",
    "\n",
    "        print(\"Ocean warming data saved to ocean_warming_data.csv\")\n",
    "    else:\n",
    "        print(f\"API request failed with status code: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSIRO (Commonwealth Scientific and Industrial Research Organization) Data \n",
    " This data contains “cumulative changes in sea level for the world’s oceans since 1880, based on a combination of long-term tide gauge measurements and recent satellite measurements. It shows average absolute sea level change, which refers to the height of the ocean surface, regardless of whether nearby land is rising or falling. The data is recorded in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jenifer - Historical Sea Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct CSV download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to load \n",
    "historical_sea_level_to_load = Path(\"../../Resources/sea-level-rise-historical.csv\")\n",
    "\n",
    "# read CSV\n",
    "sealevelrise_data_historical = pd.read_csv(historical_sea_level_to_load)\n",
    "\n",
    "# convert to pandas df\n",
    "slr_data_historical = pd.DataFrame(sealevelrise_data_historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical global avg sea level rise in cm\n",
    "slr_data_historical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jenifer - Sea Level Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct CSV download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file to load \n",
    "predictions_sea_level_to_load = Path(\"../../Resources/sea-level-rise-predictions.csv\")\n",
    "\n",
    "# read CSV\n",
    "sealevelrise_data_predictions = pd.read_csv(predictions_sea_level_to_load)\n",
    "\n",
    "# convert to pandas df\n",
    "slr_data_predictions = pd.DataFrame(sealevelrise_data_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted global avg sea level rise in cm\n",
    "slr_data_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictions Global SLR - 10 cities\n",
    "\n",
    "# Get a list of all of our columns for easy reference\n",
    "slr_data_predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific Latitude and Longitude values\n",
    "target_latitudes = [40.7, 47.6, 44.67, 34.23, 46.22, -17.6, 21, 25.77, 1.1, 59.55]\n",
    "target_longitudes = [-74.01, -122.34, -63.58, -77.95, -60.25, 177.44, -97.33, -80.13, 154.78, -139.73]\n",
    "\n",
    "# Create a condition to filter rows based on specified Latitudes and Longitudes\n",
    "condition = (slr_data_predictions['Latitude'].isin(target_latitudes)) & \\\n",
    "            (slr_data_predictions['Longitude'].isin(target_longitudes))\n",
    "\n",
    "# Select the desired columns and rows based on the condition\n",
    "selected_columns = ['Site', 'Scenario', 'Latitude', 'Longitude', \n",
    "                    'Background RSL rate (mm/yr)', 'RSL in 2000 (cm)', \n",
    "                    'RSL in 2010 (cm)', 'RSL in 2020 (cm)', 'RSL in 2030 (cm)', \n",
    "                    'RSL in 2040 (cm)', 'RSL in 2050 (cm)', 'RSL in 2060 (cm)', \n",
    "                    'RSL in 2070 (cm)', 'RSL in 2080 (cm)', 'RSL in 2090 (cm)', \n",
    "                    'RSL in 2100 (cm)', 'RSL in 2120 (cm)', 'RSL in 2150 (cm)', \n",
    "                    'RSL in 2200 (cm)']\n",
    "\n",
    "select_cities_preddf = slr_data_predictions.loc[condition, selected_columns]\n",
    "select_cities_preddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows for which you want to calculate the average\n",
    "\n",
    "# 1. NEW YORK\n",
    "newyork_rows = select_cities_preddf.iloc[0:18]\n",
    "# newyork_rows\n",
    "newyork_meandata = newyork_rows.mean()\n",
    "# newyork_meandata\n",
    "\n",
    "# 2. HALIFAX\n",
    "halifax_rows = select_cities_preddf.iloc[18:36]\n",
    "# halifax_rows\n",
    "halifax_meandata = halifax_rows.mean()\n",
    "# halifax_meandata\n",
    "\n",
    "# 3. SEATTLE\n",
    "seattle_rows = select_cities_preddf.iloc[36:54]\n",
    "# seattle_rows\n",
    "seattle_meandata = seattle_rows.mean()\n",
    "# seattle_meandata\n",
    "\n",
    "# 4. MIAMI BEACH\n",
    "miamibeach_rows = select_cities_preddf.iloc[54:72]\n",
    "# miamibeach_rows\n",
    "miamibeach_meandata = miamibeach_rows.mean()\n",
    "# miamibeach_meandata\n",
    "\n",
    "# 5. WILMINGTON\n",
    "wilmington_rows = select_cities_preddf.iloc[72:90]\n",
    "# wilmington_rows\n",
    "wilmington_meandata = wilmington_rows.mean()\n",
    "# wilmington_meandata\n",
    "\n",
    "# 6. YAKUTAT\n",
    "yakutat_rows = select_cities_preddf.iloc[90:108]\n",
    "# yakutat_rows\n",
    "yakutat_meandata = yakutat_rows.mean()\n",
    "# yakutat_meandata\n",
    "\n",
    "# 7. TUXPAN\n",
    "tuxpan_rows = select_cities_preddf.iloc[108:126]\n",
    "# tuxpan_rows\n",
    "tuxpan_meandata = tuxpan_rows.mean()\n",
    "# tuxpan_meandata\n",
    "\n",
    "# 8. NORTH SYDNEY\n",
    "northsydney_rows = select_cities_preddf.iloc[126:144]\n",
    "# northsydney_rows\n",
    "northsydney_meandata = northsydney_rows.mean()\n",
    "# northsydney_meandata\n",
    "\n",
    "# 9. KAPINGAMARANGI\n",
    "kapingamarangi_rows = select_cities_preddf.iloc[144:162]\n",
    "# kapingamarangi_rows\n",
    "kapingamarangi_meandata = kapingamarangi_rows.mean()\n",
    "# kapingamarangi_meandata\n",
    "\n",
    "# 10. LAUTOKA\n",
    "lautoka_rows = select_cities_preddf.iloc[162:180]\n",
    "# lautoka_rows\n",
    "lautoka_meandata = lautoka_rows.mean()\n",
    "# lautoka_meandata\n",
    "# type(lautoka_meandata)\n",
    "\n",
    "\n",
    "# create a df using all the averages for the cities\n",
    "tencities_slr_dict = {\n",
    "    'New York': newyork_meandata, \n",
    "    'Seattle': seattle_meandata,\n",
    "    'Halifax': halifax_meandata, \n",
    "    'Wilmington': wilmington_meandata, \n",
    "    'North Sydney': northsydney_meandata,\n",
    "    'Lautoka': lautoka_meandata,\n",
    "    'Tuxpan': tuxpan_meandata,\n",
    "    'Miami Beach': miamibeach_meandata,\n",
    "    'Kapingamarangi': kapingamarangi_meandata, \n",
    "    'Yakutat': yakutat_meandata\n",
    "}\n",
    "\n",
    "tencities_meanslr = pd.DataFrame(tencities_slr_dict)\n",
    "tencities_meanslr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrame using .transpose() method\n",
    "global_meanslr = tencities_meanslr.transpose()\n",
    "global_meanslr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as CSV\n",
    "global_meanslr.to_csv('../../Resources/global_meanslr_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, May  7 2023, 23:32:45) \n[Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
