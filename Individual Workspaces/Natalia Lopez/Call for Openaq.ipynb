{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from pandas import json_normalize\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call for Openaq\n",
    "url = \"https://api.openaq.org/v2/locations?parameters=pm25\"\n",
    "aq_response = requests.get(url)\n",
    "aq_data = aq_response.json()\n",
    "aq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aq_response.status_code == 200:\n",
    "    aq_data = aq_response.json()\n",
    "else:\n",
    "    print(\"Failed to fetch data from the API.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON to a File\n",
    "with open('aq_data.json', 'w') as json_file:\n",
    "    json.dump(aq_data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('aq_data.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to CSV\n",
    "aq_csv_data = []\n",
    "for item in aq_data ['results']:\n",
    "    aq_csv_data.append([item['id'], item['city'], item['name'], item['country'], item['parameters']])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV to \"resources\" Folder\n",
    "# Define the CSV file\n",
    "aq_csv_file_path = os.path.join('../../Resources/aq_data.csv')\n",
    "\n",
    "with open(aq_csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['id', 'city', 'name', 'country', 'parameters'])\n",
    "    csv_writer.writerows(aq_csv_data)\n",
    "\n",
    "print(f'CSV file saved to: {aq_csv_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the dataframe to separate columns parameters and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('aq_data.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'results' list\n",
    "results = json_data['results']\n",
    "\n",
    "# Flatten the JSON data into a list of dictionaries\n",
    "flattened_data = []\n",
    "for entry in results:\n",
    "    flat_entry = {}\n",
    "    for key, value in entry.items():\n",
    "        if isinstance(value, dict):\n",
    "            for nested_key, nested_value in value.items():\n",
    "                flat_entry[f'{key}_{nested_key}'] = nested_value\n",
    "        else:\n",
    "            flat_entry[key] = value\n",
    "            flattened_data.append(flat_entry)\n",
    "\n",
    "# Create a DataFrame from the flattened data\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('aq_data.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for each row with all keys and corresponding values\n",
    "extracted_data = []\n",
    "for item in aq_data['results']:\n",
    "    extracted_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the extracted data\n",
    "df2 = pd.DataFrame(extracted_data)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open('aq_data.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json_data['results']\n",
    "\n",
    "results_df = pd.DataFrame(results).explode('parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.json_normalize(results_df['parameters']).set_index(results_df.index)\n",
    "parameters = parameters.drop(['id', 'manufacturers'], axis=1)\n",
    "results_df = results_df.drop('parameters', axis=1)\n",
    "results_df = pd.concat([results_df, parameters], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.json_normalize(results_df['coordinates']).set_index(results_df.index)\n",
    "results_df = results_df.drop('coordinates', axis=1)\n",
    "results_df = pd.concat([results_df, coordinates], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufacturers = pd.json_normalize(results_df['manufacturers'].explode()).set_index(results_df.index)\n",
    "results_df = results_df.drop('manufacturers', axis=1)\n",
    "results_df = pd.concat([results_df, manufacturers], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to delete\n",
    "columns_to_delete = ['entity', 'sources', 'isMobile', 'isAnalysis', 'sensorType', 'lastUpdated', 'firstUpdated']\n",
    "\n",
    "# Delete the specified columns\n",
    "results_df = results_df.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified dataset to a new CSV file\n",
    "results_df.to_csv('../../Resources/cleaned_aq_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of unique values in the specified column\n",
    "unique_values = results_df['parameter'].unique()\n",
    "for value in unique_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check each parameter separately to look into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'pm10'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "pm12_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "pm12_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm12_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'no2'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "no2_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "no2_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'co'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "co_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "co_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "# pm1 = Particulate matter (PM) less than 1 micron in size is called PM1 (sometimes PM1. 0). PM1 is considered especially \n",
    "# dangerous due to its extremely small size. The smaller the diameter of a particle, the more harm it can typically cause.\n",
    "target_parameter = 'pm1'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "pm1_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "pm1_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm1_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'temperature'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "temperature_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "temperature_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um050'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um050_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um050_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um050_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'pressure'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "pressure_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "pressure_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um005'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um005_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um005_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um005_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'humidity'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "humidity_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "humidity_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um025'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um025_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um025_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um025_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um100'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um100_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um100_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um100_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um003'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um003_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um003_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um003_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'um010'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "um010_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "um010_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um010_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "target_parameter = 'pm25'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "pm25_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "pm25_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameter value you want to extract\n",
    "# volatile organic compounds (vocs)\n",
    "target_parameter = 'voc'\n",
    "\n",
    "# Filter the rows with the specific parameter value\n",
    "voc_dataset = results_df[results_df['parameter'] == target_parameter]\n",
    "voc_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date formatting for CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Replace 1850 with the valid year you have\n",
    "year = 1850\n",
    "\n",
    "try:\n",
    "    date_object = datetime(year, 1, 1)\n",
    "    print(\"Date:\", date_object.strftime(\"%Y-%m-%d\"))\n",
    "except ValueError:\n",
    "    print(\"Invalid year\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_python_requirements_osx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
